{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizacion con MAPL + DicsBvals\n",
    "\n",
    "$ G \\leftarrow train(\\{(HR_i, LR_i)\\}_i) \\  \\forall i=1,2 ... n\\_samples \\hspace{2cm} con \\ LR_i = downsampling(HR_i)$\n",
    "\n",
    "$ M \\leftarrow mapl(Y^{lr}.gtab) $\n",
    "\n",
    "$ \\min_{Y^{hr},C} \\{ (\\sum_{b\\in bvals} ||G_{b}Y_{b}^{hr} - Y_{b}^{lr}||^2) + || Y^{lr} - MC||^2 + ||C||_{1} \\}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import img_utils\n",
    "import seaborn as sns\n",
    "import utils.math_utils as mat_utils\n",
    "#import nibabel as nib\n",
    "import mapmri.mapmri as mp\n",
    "#from dipy.core.gradients import gradient_table\n",
    "import cvxpy as cvx\n",
    "reload(img_utils)\n",
    "import load.hcp_img_loader as hcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sample(index, numbers, loader_func, bval=None, bvalpos=None,  scale=2):\n",
    "    img, gtab = loader_func(index, numbers, bval, bvalpos)\n",
    "    lr, lr_affine = img_utils.downsampling(img, scale)\n",
    "    return img.get_data(), lr, gtab\n",
    "\n",
    "def get_sample_maker(numbers, loader_func, bval=None, bvalpos=None, scale=2):\n",
    "    return lambda index : get_sample(index, numbers, loader_func, bval, bvalpos,  scale)\n",
    "\n",
    "def mm(A, cast_int=True):\n",
    "    if cast_int :\n",
    "        return (int(A.min()), int(A.max()))\n",
    "    else:\n",
    "        return (A.min(), A.max())\n",
    "    \n",
    "def buildT(sample_getter, n_samples):\n",
    "    noised_hr, noised_lr = sample_getter(0)\n",
    "    X = img_utils.column_this(noised_lr)\n",
    "    Y = img_utils.column_this(noised_hr)\n",
    "    for i in range(1, n_samples):\n",
    "        noised_hr, noised_lr = sample_getter(i)\n",
    "        X = img_utils.append_column(X, noised_lr)\n",
    "        Y = img_utils.append_column(Y, noised_hr)\n",
    "    return X, Y\n",
    "\n",
    "def buildT_grouping_by_q(sample_getter, n_samples, bvals_needed):\n",
    "    \"\"\"\n",
    "    Genera tantos conjuntos de entrenamiento como \n",
    "    bvals distintos tenga el volumne\n",
    "    \"\"\"\n",
    "    hr, lr, gtab = sample_getter(0)\n",
    "    bs = bvals_needed[0:hr.shape[3]]\n",
    "    \n",
    "    dicX = split_by_bval(lr, bs, gtab)\n",
    "    dicY = split_by_bval(hr, bs, gtab)\n",
    "    for i in range(1, n_samples):\n",
    "        hr, lr, gtab = sample_getter(i)\n",
    "        dicX = split_by_bval(lr, bs, gtab, dicX)\n",
    "        dicY = split_by_bval(hr, bs, gtab, dicY)\n",
    "    return dicX, dicY\n",
    "\n",
    "def split_by_bval(img, bvals_needed, gtab, res=None):\n",
    "    \"\"\"\n",
    "    Dada una imagen separa la cuarta dimension segun su vbal\n",
    "    Y por cada una hace un vector columna\n",
    "    \"\"\"\n",
    "    if res is None:\n",
    "        res = dict((b, None) for b in bvals_needed)\n",
    "        \n",
    "    for i in xrange(len(gtab.bvals)):\n",
    "        b = gtab.bvals[i]\n",
    "        if b not in bvals_needed :\n",
    "            continue\n",
    "        \n",
    "        XorY = res[b]\n",
    "        if XorY is None:\n",
    "            res[b] = img_utils.column_this(img[:,:,:,i])\n",
    "        else:\n",
    "            res[b] = img_utils.append_column(XorY, img[:,:,:,i])\n",
    "    return res\n",
    "\n",
    "    \n",
    "\n",
    "## Example of use\n",
    "#buildT(get_sample_maker(numbers, scale), n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem definition\n",
    "\n",
    "\n",
    "$ \\min_{Y^{hr},C} \\{ (\\sum_{b\\in bvals} ||G_{b}Y_{b}^{hr} - Y_{b}^{lr}||^2) + || Y^{lr} - S_0*\\phi*C||^2 + ||C||_{1} \\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapMri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getM(radial_order, mu, gtab, tau):\n",
    "    r'''Recovers the reconstructed signal for any qvalue array or\n",
    "        gradient table.\n",
    "        '''\n",
    "    qvals = np.sqrt(gtab.bvals / tau) / (2 * np.pi)\n",
    "    q = qvals[:, None] * gtab.bvecs\n",
    "    M = mp.mapmri_isotropic_phi_matrix(radial_order, mu[0], q)\n",
    "    return  M\n",
    "\n",
    "def get_mapl_params(gtab, radial_order = 4):\n",
    "    #Fiteo el model\n",
    "    map_model = mp.MapmriModel(gtab,\n",
    "                                radial_order=radial_order,\n",
    "                                laplacian_regularization=True,\n",
    "                                laplacian_weighting=0.2,\n",
    "                                anisotropic_scaling=False,\n",
    "                                dti_scale_estimation=False)\n",
    "    # Fiteo la data\n",
    "    #map_model_fit = map_model.fit(i_hr)\n",
    "    tau = map_model.tau\n",
    "    mu = map_model.mu\n",
    "    print 'mu.shape', mu.shape\n",
    "    M = getM(radial_order, mu, gtab, tau)\n",
    "    return M, tau, mu\n",
    "\n",
    "def mapl_predict(gtab, C_or_Cvec, M, tau, Nx=None, Ny=None, Nz=None):\n",
    "    \"\"\"\n",
    "       This method can be used to predit a given q-points (within gtab)\n",
    "       For a previous fited C or a cvxpy dual variable definition\n",
    "    \"\"\"\n",
    "    is_cvxpy = isinstance(C_or_Cvec, cvx.Variable)\n",
    "    print 'M.shape', M.shape, 'C.size', C_or_Cvec.size\n",
    "    Nb, Nc = M.shape\n",
    "    vhr, Nc = C_or_Cvec.shape if hasattr(C_or_Cvec, 'shape') else C_or_Cvec.size\n",
    "    #vhr = Nx*Ny*Nz\n",
    "    \n",
    "    Cvec = C_or_Cvec\n",
    "    if not is_cvxpy :\n",
    "        Cvec = C.reshape((vhr, Nc), order='F')\n",
    "         \n",
    "    if is_cvxpy :\n",
    "        E = (M * Cvec.T).T\n",
    "    else:\n",
    "        E = np.dot(M, Cvec.T).T\n",
    "        \n",
    "    if not is_cvxpy :\n",
    "        print E.shape,(Nx, Ny, Nz, Nb) \n",
    "        E = E.reshape((Nx, Ny, Nz, Nb), order='F')\n",
    "    #else:\n",
    "    #    E = E.reshape(-1, order='F')\n",
    "        \n",
    "    return E\n",
    "\n",
    "\n",
    "def cvxpy_mapl(gtab, M, tau, Nc):\n",
    "    Nx, Ny, Nz, bval = i_hr.shape\n",
    "    vhr = Nx*Ny*Nz\n",
    "    vhrb = vhr*bval\n",
    "    \n",
    "    # Image to fit\n",
    "    cvxC = cvx.Variable(vhr, Nc)\n",
    "\n",
    "    cvxMaplE = mapl_predict(gtab, cvxC, M, tau)\n",
    "    #print 'E.size', cvxE.size\n",
    "\n",
    "    \n",
    "    ## objective\n",
    "    #obj = cvx.Minimize(cvx.sum_squares(cvxE-YhrMap) + alpha*cvx.norm1(cvxC))\n",
    "\n",
    "    return cvxMaplE, cvxC\n",
    "    ## some constraints\n",
    "    # pos_cons =[ cvxM*cvxC[i,:].T >= 0  for i in xrange(vhr) ]\n",
    "    # max_cons =[ cvxM*cvxC[i,:].T*cvxS0[i] <= i_hr.max() for i in xrange(vhr) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "def define_problem_with_mapl(i_lr, i_hr_shape, dic_G, M, tau, gtab, scale):\n",
    "    Nx, Ny, Nz, bval = i_hr_shape\n",
    "    _, Nc = M.shape\n",
    "    vlr = Nx*Ny*Nz/(scale**3)\n",
    "    vlrb = vlr*bval\n",
    "    vhr = Nx*Ny*Nz\n",
    "    vhrb = vhr*bval\n",
    "      \n",
    "    ## Hr volumes\n",
    "    #Yhr = cvx.Variable(vhrb, 1)\n",
    "    #Yhr.value = np.ones((vhrb, 1))*i_lr.mean()\n",
    "    \n",
    "    ## LR volumes\n",
    "    Ylr = cvx.Parameter(vlr*bval, 1, sign=\"positive\")\n",
    "    Ylr.value = i_lr.reshape((vlr*bval, 1), order='F')\n",
    "    \n",
    "    ## Downsamplings matrixs\n",
    "    G = dict((group, cvx.Parameter(*dic_G[group].shape)) for group in dic_G.keys())\n",
    "    for group in dic_G.keys():\n",
    "        G[group].value = dic_G[group]\n",
    "    \n",
    "    ## MAPL params\n",
    "    cvxC = cvx.Variable(vhr, Nc)\n",
    "    cvxMaplE = (M * Cvec.T).T\n",
    "    # Hr image in row by b-val\n",
    "    YhrMapl = cvx.reshape(Yhr, vhr,bval).T\n",
    "    # Mapl dual expression\n",
    "    cvxMaplDualExp = cvx.sum_squares(cvxMaplE-YhrMapl)\n",
    "    \n",
    "    \n",
    "    ## Mapl dual expression\n",
    "    #cvxMaplDualExp = cvx.sum_squares(cvxMaplE-YhrMapl)\n",
    "    \n",
    "    ## Mapl weight\n",
    "    betha = cvx.Parameter(value=.23, sign='positive')\n",
    "    ## Sparcity weight\n",
    "    alpha = cvx.Parameter(value=.15, sign='positive')\n",
    "    ## Fidelity weight\n",
    "    gamma = cvx.Parameter(value=.62, sign='positive')\n",
    "    \n",
    "    #epsilon = cvx.Parameter(value=1, sign='positive')\n",
    "    #constraints = [cvxMaplDualExp <= epsilon]\n",
    "    \n",
    "    # Constraints\n",
    "    #constraints = [Yhr >= 0, Yhr <= i_lr.max()]\n",
    "    \n",
    "    \n",
    "    ## Fidelity expression\n",
    "    fidelity_list = []\n",
    "    for i in xrange(bval):\n",
    "        b = gtab.bvals[i]\n",
    "        b_offset_lr = i*vlr\n",
    "        Ylr_b = Ylr[b_offset_lr:b_offset_lr+vlr]\n",
    "        #                     (vlr,vhr)*(vhr,1) - (vlr,1)\n",
    "        print G[b].shape, cvxMaplE.shape\n",
    "        fid_b = cvx.sum_squares(G[b]*(cvxMaplE[i, :]).T - Ylr_b)\n",
    "        fidelity_list.append(fid_b)\n",
    "        \n",
    "    print '#fidelity sums =', len(fidelity_list)\n",
    "    cvxFidelityExp = sum(fidelity_list)\n",
    "    \n",
    "    # Form objective.\n",
    "    obj = cvx.Minimize(gamma*cvxFidelityExp + alpha*cvx.norm1(cvxC))\n",
    "    \n",
    "    # Form and solve problem.\n",
    "    prob = cvx.Problem(obj)\n",
    "    \n",
    "    return prob, cvx.reshape((M*cvxC.T).T, vhrb,1), Ylr, cvxC, G \n",
    "\n",
    "\"\"\"\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def define_problem_with_mapl(i_lr, i_hr_shape, dic_G, M, tau, gtab, scale):\n",
    "    Nx, Ny, Nz, bval = i_hr_shape\n",
    "    _, Nc = M.shape\n",
    "    vlr = Nx*Ny*Nz/(scale**3)\n",
    "    vlrb = vlr*bval\n",
    "    vhr = Nx*Ny*Nz\n",
    "    vhrb = vhr*bval\n",
    "      \n",
    "    ## Hr volumes\n",
    "    Yhr = cvx.Variable(vhrb, 1)\n",
    "    #Yhr.value = np.ones((vhrb, 1))*i_lr.mean()\n",
    "    \n",
    "    ## LR volumes\n",
    "    Ylr = cvx.Parameter(vlr*bval, 1, sign=\"positive\")\n",
    "    Ylr.value = i_lr.reshape((vlr*bval, 1), order='F')\n",
    "    \n",
    "    ## Downsamplings matrixs\n",
    "    G = dic_G\n",
    "    \n",
    "    ## MAPL params\n",
    "    cvxC = cvx.Variable(vhr, Nc)\n",
    "    #    M:(Nb,Nc) Cvec:(vhr, Nc)  cvxMaplE: (vhr,Nb)\n",
    "    cvxMaplE = (M * cvxC.T).T\n",
    "    # Hr image in row by b-val\n",
    "    YhrMapl = cvx.reshape(Yhr, vhr, bval)\n",
    "    # Mapl dual expression\n",
    "    cvxMaplDualExp = cvx.sum_squares(cvxMaplE-YhrMapl)\n",
    "    \n",
    "    ## Mapl weight\n",
    "    betha = cvx.Parameter(value=.23, sign='positive')\n",
    "    ## Sparcity weight\n",
    "    alpha = cvx.Parameter(value=.15, sign='positive')\n",
    "    ## Fidelity weight\n",
    "    gamma = cvx.Parameter(value=.62, sign='positive')\n",
    "    \n",
    "    # Constraints\n",
    "    constraints = []\n",
    "    #constraints.append(Yhr >= 0, Yhr <= i_lr.max())\n",
    "    \n",
    "    ## Fidelity expression\n",
    "    fidelity_list = []\n",
    "    for i in xrange(bval):\n",
    "        b = gtab.bvals[i]\n",
    "        b_offset_hr, b_offset_lr = i*vhr, i*vlr\n",
    "        Yhr_b = Yhr[b_offset_hr:b_offset_hr+vhr]\n",
    "        Ylr_b = Ylr[b_offset_lr:b_offset_lr+vlr]\n",
    "        fid_b = cvx.sum_squares(G[b]*Yhr_b - Ylr_b)\n",
    "        fidelity_list.append(fid_b)\n",
    "        \n",
    "    print '#fidelity sums =', len(fidelity_list)\n",
    "    cvxFidelityExp = sum(fidelity_list)\n",
    "    \n",
    "    # Form objective.\n",
    "    obj = cvx.Minimize(gamma*cvxFidelityExp + betha*cvxMaplDualExp + alpha*cvx.norm1(cvxC))\n",
    "    \n",
    "    # Form and solve problem.\n",
    "    prob = cvx.Problem(obj, constraints)\n",
    "    \n",
    "    return prob, Yhr, Ylr, cvxC, G \n",
    "\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def solveMin(i_lr, i_hr_shape, dic_G, M, tau, gtab, scale=2, max_iters=1500, verbose=False):\n",
    "    Nx, Ny, Nz, Nb = i_hr_shape\n",
    "    Nb, Nc = M.shape\n",
    "    prob, Yhr, Ylr, cvxC, G = define_problem_with_mapl(\n",
    "                                i_lr, \n",
    "                                i_hr_shape, \n",
    "                                dic_G, \n",
    "                                M, tau,\n",
    "                                gtab,\n",
    "                                scale)\n",
    "     \n",
    "    start_time = time.time()\n",
    "    print 'asasasa'\n",
    "    res = prob.solve(solver='SCS', max_iters=max_iters, eps=0.50e-01, verbose=verbose )  # Returns the optimal value.\n",
    "    seg = time.time() - start_time\n",
    "\n",
    "    minutes = int(seg / 60)\n",
    "    print(\"--- time of optimization : %d' %d'' ---\" % (minutes , seg%60))\n",
    "    print \"--- status:\", prob.status, \"optimal value\", prob.value\n",
    "    print \n",
    "\n",
    "    # Change dimension of result representation\n",
    "    C, A = None, None\n",
    "    if Yhr.value is None :\n",
    "        #Yhr.value = np.ones(i_hr_shape)\n",
    "        print 'FRECONSTRUCTION FAIL :('\n",
    "        A = np.zeros(i_hr_shape,dtype='float32')\n",
    "    else:    \n",
    "        A = np.asarray(Yhr.value, dtype='float32').reshape(i_hr_shape, order='F')\n",
    "        C = np.asarray(cvxC.value, dtype='float32').reshape((Nx, Ny, Nz, Nc), order='F')\n",
    " \n",
    "        \n",
    "    return A, C, seg, prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the problem and cross-validation (leave one out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/lgomez/home/anaconda2/lib/python2.7/site-packages/skimage/filter/__init__.py:6: skimage_deprecation: The `skimage.filter` module has been renamed to `skimage.filters`.  This placeholder module will be removed in v0.13.\n",
      "  warn(skimage_deprecation('The `skimage.filter` module has been renamed '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Leaving out: # 100307\n",
      "= Training and fiting ...\n",
      "Training with bval= 1985.0 X.shape  (1728, 5)   Y.shape (216, 5)\n",
      "Training with bval= 3010.0 X.shape  (1728, 3)   Y.shape (216, 3)\n",
      "Training with bval= 995.0 X.shape  (1728, 21)   Y.shape (216, 21)\n",
      "Training with bval= 5.0 X.shape  (1728, 9)   Y.shape (216, 9)\n",
      "Training with bval= 1990.0 X.shape  (1728, 7)   Y.shape (216, 7)\n",
      "Training with bval= 1000.0 X.shape  (1728, 8)   Y.shape (216, 8)\n",
      "Training with bval= 2985.0 X.shape  (1728, 3)   Y.shape (216, 3)\n",
      "Training with bval= 1995.0 X.shape  (1728, 8)   Y.shape (216, 8)\n",
      "Training with bval= 1005.0 X.shape  (1728, 4)   Y.shape (216, 4)\n",
      "Training with bval= 2990.0 X.shape  (1728, 7)   Y.shape (216, 7)\n",
      "Training with bval= 2000.0 X.shape  (1728, 9)   Y.shape (216, 9)\n",
      "Training with bval= 2995.0 X.shape  (1728, 9)   Y.shape (216, 9)\n",
      "Training with bval= 2005.0 X.shape  (1728, 5)   Y.shape (216, 5)\n",
      "Training with bval= 3000.0 X.shape  (1728, 2)   Y.shape (216, 2)\n",
      "Training with bval= 3005.0 X.shape  (1728, 12)   Y.shape (216, 12)\n",
      "Training with bval= 990.0 X.shape  (1728, 6)   Y.shape (216, 6)\n",
      "mu.shape (3,)\n",
      "= Solving optimization problem ...\n",
      "#fidelity sums = 40\n",
      "asasasa\n",
      "----------------------------------------------------------------------------\n",
      "\tSCS v1.2.6 - Splitting Conic Solver\n",
      "\t(c) Brendan O'Donoghue, Stanford University, 2012-2016\n",
      "----------------------------------------------------------------------------\n",
      "Lin-sys: sparse-indirect, nnz in A = 16671826, CG tol ~ 1/iter^(2.00)\n",
      "eps = 5.00e-03, alpha = 1.50, max_iters = 1500, normalize = 1, scale = 1.00\n",
      "Variables n = 145193, constraints m = 153874\n",
      "Cones:\tlinear vars: 76032\n",
      "\tsoc vars: 77842, soc blks: 41\n",
      "Setup time: 5.79e-01s\n",
      "----------------------------------------------------------------------------\n",
      " Iter | pri res | dua res | rel gap | pri obj | dua obj | kap/tau | time (s)\n",
      "----------------------------------------------------------------------------\n",
      "     0|      inf       inf      -nan      -inf       inf       inf  2.86e+00 \n",
      "   100| 2.68e-02  1.09e-02  3.20e-02  1.46e+06  1.55e+06  9.04e-10  9.18e+01 \n",
      "   200| 3.44e-02  1.65e-02  2.11e-02  1.86e+06  1.94e+06  8.13e-10  2.18e+02 \n",
      "   300| 4.15e-02  2.12e-02  1.33e-02  2.43e+06  2.50e+06  0.00e+00  3.58e+02 \n",
      "   400| 5.13e-02  2.34e-02  8.70e-03  3.31e+06  3.37e+06  7.75e-10  5.08e+02 \n",
      "   500| 5.33e-02  2.47e-02  4.82e-03  4.40e+06  4.45e+06  8.22e-10  6.62e+02 \n",
      "   600| 5.42e-02  2.45e-02  2.77e-03  5.80e+06  5.83e+06  7.69e-10  8.27e+02 \n",
      "   700| 5.81e-02  2.50e-02  2.02e-03  7.06e+06  7.09e+06  6.20e-10  9.86e+02 \n",
      "   800| 6.46e-02  2.42e-02  1.10e-03  8.66e+06  8.68e+06  9.43e-10  1.15e+03 \n",
      "   900| 6.29e-02  2.46e-02  8.50e-04  1.01e+07  1.01e+07  6.69e-10  1.31e+03 \n",
      "  1000| 5.90e-02  2.49e-02  6.30e-04  1.16e+07  1.17e+07  9.15e-10  1.48e+03 \n",
      "  1100| 5.53e-02  2.54e-02  4.61e-04  1.30e+07  1.30e+07  1.19e-09  1.65e+03 \n",
      "  1200| 5.39e-02  2.52e-02  4.06e-04  1.45e+07  1.46e+07  7.59e-10  1.82e+03 \n",
      "  1300| 5.26e-02  2.52e-02  3.00e-04  1.59e+07  1.59e+07  9.31e-10  2.00e+03 \n",
      "  1400| 5.13e-02  2.45e-02  2.47e-04  1.75e+07  1.75e+07  1.14e-09  2.17e+03 \n",
      "  1500| 4.92e-02  2.43e-02  1.23e-04  1.88e+07  1.88e+07  6.74e-10  2.34e+03 \n",
      "----------------------------------------------------------------------------\n",
      "Status: Solved/Inaccurate\n",
      "Hit max_iters, solution may be inaccurate\n",
      "Timing: Solve time: 2.34e+03s\n",
      "\tLin-sys: avg # CG iterations: 31.93, avg solve time: 1.55e+00s\n",
      "\tCones: avg projection time: 1.48e-04s\n",
      "----------------------------------------------------------------------------\n",
      "Error metrics:\n",
      "dist(s, K) = 1.1642e-06, dist(y, K*) = 2.1828e-11, s'y/|s||y| = -1.5975e-14\n",
      "|Ax + s - b|_2 / (1 + |b|_2) = 4.9241e-02\n",
      "|A'y + c|_2 / (1 + |c|_2) = 2.4344e-02\n",
      "|c'x + b'y| / (1 + |c'x| + |b'y|) = 1.2272e-04\n",
      "----------------------------------------------------------------------------\n",
      "c'x = 18787598.8626, -b'y = 18792210.6838\n",
      "============================================================================\n",
      "--- time of optimization : 39' 15'' ---\n",
      "--- status: optimal_inaccurate optimal value 18787598.8626\n",
      "\n",
      "doing ^i_lr[0]= G(5)*i_hr[0]\n",
      "doing ^i_lr[1]= G(1000)*i_hr[1]\n",
      "doing ^i_lr[2]= G(1995)*i_hr[2]\n",
      "doing ^i_lr[3]= G(3005)*i_hr[3]\n",
      "doing ^i_lr[4]= G(995)*i_hr[4]\n",
      "doing ^i_lr[5]= G(2995)*i_hr[5]\n",
      "doing ^i_lr[6]= G(2005)*i_hr[6]\n",
      "doing ^i_lr[7]= G(990)*i_hr[7]\n",
      "doing ^i_lr[8]= G(1990)*i_hr[8]\n",
      "doing ^i_lr[9]= G(3000)*i_hr[9]\n",
      "doing ^i_lr[10]= G(1000)*i_hr[10]\n",
      "doing ^i_lr[11]= G(1985)*i_hr[11]\n",
      "doing ^i_lr[12]= G(2990)*i_hr[12]\n",
      "doing ^i_lr[13]= G(1005)*i_hr[13]\n",
      "doing ^i_lr[14]= G(1995)*i_hr[14]\n",
      "doing ^i_lr[15]= G(2995)*i_hr[15]\n",
      "doing ^i_lr[16]= G(5)*i_hr[16]\n",
      "doing ^i_lr[17]= G(995)*i_hr[17]\n",
      "doing ^i_lr[18]= G(2000)*i_hr[18]\n",
      "doing ^i_lr[19]= G(3010)*i_hr[19]\n",
      "doing ^i_lr[20]= G(3005)*i_hr[20]\n",
      "doing ^i_lr[21]= G(995)*i_hr[21]\n",
      "doing ^i_lr[22]= G(2005)*i_hr[22]\n",
      "doing ^i_lr[23]= G(995)*i_hr[23]\n",
      "doing ^i_lr[24]= G(1990)*i_hr[24]\n",
      "doing ^i_lr[25]= G(2985)*i_hr[25]\n",
      "doing ^i_lr[26]= G(1005)*i_hr[26]\n",
      "doing ^i_lr[27]= G(2000)*i_hr[27]\n",
      "doing ^i_lr[28]= G(3005)*i_hr[28]\n",
      "doing ^i_lr[29]= G(995)*i_hr[29]\n",
      "doing ^i_lr[30]= G(1995)*i_hr[30]\n",
      "doing ^i_lr[31]= G(2990)*i_hr[31]\n",
      "doing ^i_lr[32]= G(5)*i_hr[32]\n",
      "doing ^i_lr[33]= G(3005)*i_hr[33]\n",
      "doing ^i_lr[34]= G(995)*i_hr[34]\n",
      "doing ^i_lr[35]= G(2000)*i_hr[35]\n",
      "doing ^i_lr[36]= G(990)*i_hr[36]\n",
      "doing ^i_lr[37]= G(1985)*i_hr[37]\n",
      "doing ^i_lr[38]= G(2990)*i_hr[38]\n",
      "doing ^i_lr[39]= G(995)*i_hr[39]\n",
      "= Calculating metrics...\n",
      "\n",
      "\n",
      " === TOTAL TIME : 39' 15\"\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import experimento1_funciones as e1f\n",
    "reload(e1f)\n",
    "\n",
    "RES_BASE_FOLDER = './resultados/exp5/'\n",
    "VMIN, VMAX=-50, 2500\n",
    "\n",
    "voi_hr_shape = (12, 12, 12, 6)\n",
    "voi_lr_shape = (6, 6, 6, 6)\n",
    "#subjects = [100307, 100408, 180129, 180432, 180836, 180937]\n",
    "subjects = [100307, 100408, 180129]\n",
    "\n",
    "bvals2000pos = [18, 27, 69, 75, 101, 107]\n",
    "\n",
    "# Esto es por si quiero alguna S0\n",
    "#img_s0, gtab_s0 = load_subject_small(0, subjects, bval=5, bvalpos=bvals5pos[0:6])\n",
    "#i_hr=img.get_data()\n",
    "#S0 = img_s0.get_data()\n",
    "\n",
    "reload(hcp)\n",
    "\n",
    "#print '#Qvals: ', gtab.bvals.shape\n",
    "#print 'Bvals: ', set(gtab.bvals)\n",
    "## Con imagenes pequenas multi-shel\n",
    "loader_func = hcp.load_subject_medium\n",
    "sample_maker = get_sample_maker(subjects, loader_func, scale=2)\n",
    "## Con imagenes pequenas single-shel\n",
    "#loader_func = hcp.load_subject_small\n",
    "#sample_maker = get_sample_maker(subjects, loader_func,  bval=2000, bvalpos=bvals2000pos, scale=2)\n",
    "\n",
    "n_samples = 3\n",
    "iterations = 1\n",
    "\n",
    "# Metrics to save\n",
    "min_vals_hr_r = []\n",
    "max_vals_hr_r = []\n",
    "min_vals_lr_r = []\n",
    "max_vals_lr_r = []\n",
    "\n",
    "dif_norm_hrs=[]\n",
    "dif_norm_lrs=[]    \n",
    "Yhr_recons_norms=[]\n",
    "Ylr_recons_norms=[]  \n",
    "Yhr_norms=[]\n",
    "Ylr_norms=[]\n",
    "times = []\n",
    "optimal_vals = []\n",
    "\n",
    "## For save results\n",
    "# base_folder = RES_BASE_FOLDER\n",
    "## For NOT save results\n",
    "base_folder = None\n",
    "\n",
    "for i in range(0, iterations):\n",
    "    subjects.append(subjects.pop(0))\n",
    "    subject = str(subjects[len(subjects)-1])\n",
    "    print '== Leaving out: #', subject\n",
    "    \n",
    "    ## The one that left out to validate\n",
    "    the_one_out = len(subjects)-1\n",
    "    i_hr, i_lr, gtab = get_sample(the_one_out, subjects, loader_func, scale=2)\n",
    "    \n",
    "    ### Aca shiftear el arreglo de sujetos (train deja el ultimo afuera del entrenamiento)\n",
    "    lr_samples, hr_samples = buildT_grouping_by_q(sample_maker, n_samples, gtab.bvals) #lr, hr\n",
    "\n",
    "    #lr_samples, hr_samples = lr_samples/1589, hr_samples/1589\n",
    "    #print 'SAMPLES min/max ', lr_samples.min(),lr_samples.max(),  hr_samples.min(), hr_samples.max()\n",
    "    \n",
    "    # Build downsampling matrix\n",
    "    print '= Training and fiting ...'\n",
    "    regr, hr_train , lr_train, hr_test, lr_test = e1f.train_grouping_by_b(hr_samples, lr_samples)\n",
    "    G = dict((b,csr_matrix(regr[b].coef_)) for b in regr.keys())\n",
    "    #regr.coef_ = csr_matrix(regr.coef_)\n",
    "    \n",
    "    \n",
    "    #i_lr = lr_test.reshape(voi_lr_shape, order='F')\n",
    "    #i_hr = hr_test.reshape(voi_hr_shape, order='F')\n",
    "    \n",
    "    # Mapl params\n",
    "    M, tau, mu = get_mapl_params(gtab, radial_order = 4)\n",
    "    \n",
    "    # Minimization solve\n",
    "    # mock: A, seg = np.ones(i_hr.shape), 20\n",
    "    print '= Solving optimization problem ...'\n",
    "    A, C, seg, prob = solveMin(i_lr, i_hr.shape, G, M, tau, gtab, scale=2, max_iters=1500, verbose=True)\n",
    "    max_vals_hr_r.append(A.max())\n",
    "    min_vals_hr_r.append(A.min())\n",
    "    \n",
    "    nx, ny, nz, nb = i_lr.shape\n",
    "    B = np.zeros((nx, ny, nz, nb))\n",
    "    for i in xrange(nb):\n",
    "        b = gtab.bvals[i]\n",
    "        print 'doing ^i_lr[%d]= G(%d)*i_hr[%d]'%(i, b, i)\n",
    "        B[:,:,:,i] = (G[b]*i_hr[:,:,:,i].reshape(-1, order='F')).reshape((nx, ny, nz), order='F')\n",
    "    max_vals_lr_r.append(B.max())\n",
    "    min_vals_lr_r.append(B.min())\n",
    "    \n",
    "    # Keep parameters\n",
    "    print '= Calculating metrics...'\n",
    "    dif_norm_hr = np.linalg.norm(i_hr-A) # recons-gtrust\n",
    "    Yhr_norm = np.linalg.norm(i_hr)\n",
    "    Yhr_recons_norm = np.linalg.norm(A) #recons\n",
    "    \n",
    "    dif_norm_lr = np.linalg.norm(i_lr-B)\n",
    "    Ylr_norm = np.linalg.norm(B)\n",
    "    Ylr_recons_norm = np.linalg.norm(B)\n",
    "    \n",
    "    dif_norm_hrs.append(dif_norm_hr)\n",
    "    dif_norm_lrs.append(dif_norm_lr)\n",
    "    \n",
    "    Yhr_recons_norms.append(Yhr_recons_norm)\n",
    "    Ylr_recons_norms.append(Ylr_recons_norm)\n",
    "    \n",
    "    Yhr_norms.append(Yhr_norm)\n",
    "    Ylr_norms.append(Ylr_norm)\n",
    "    \n",
    "    times.append(seg)\n",
    "    optimal_vals.append(prob.value)\n",
    "\n",
    "    # Save the A calculated\n",
    "    if base_folder is not None:\n",
    "        name = base_folder+ \"A/\" + 'hrRec_lo' + subject\n",
    "        np.save(name, A)\n",
    "        print 'showing hr '+ subject, 'min, max',(A.min(), A.max()) \n",
    "        titles=['Reconstruida', 'Original']\n",
    "        for b in xrange(6):\n",
    "            plt = img_utils._isc(A, i_hr,b=b ,titles=titles,  vmax=VMAX, vmin=VMIN)\n",
    "            plt.savefig(name +'b'+str(b)+'.pdf')\n",
    "        print 'saved A in: ', name + str('.npy')\n",
    "        \n",
    "    # Save the B calculated\n",
    "    if base_folder is not None:\n",
    "        name = base_folder + 'lrRec_lo' + subject\n",
    "        np.save(name, B)\n",
    "        print 'showing lr '+ subject, 'min, max',(B.min(), B.max()) \n",
    "        titles=['Reconstruida', 'Original']\n",
    "        plt = img_utils._isc(B, i_lr, titles=titles,  vmax=VMAX, vmin=VMIN)\n",
    "        plt.savefig(name + '.pdf')\n",
    "        print 'saved A in: ', name + str('.npy')\n",
    "        \n",
    "    print\n",
    "    print\n",
    "\n",
    "# Log spended\n",
    "total_sec = np.array(times).sum()\n",
    "print ' === TOTAL TIME :',  str(int(total_sec//60))+\"'\", str(int(total_sec%60))+ '\"'\n",
    "\n",
    "# Persist results\n",
    "if base_folder is not None: \n",
    "    np.save(base_folder+ 'dif_norm_hrs', dif_norm_hrs)\n",
    "    np.save(base_folder+ 'dif_norm_lrs', dif_norm_lrs)\n",
    "    np.save(base_folder+ 'Yhr_recons_norms', Yhr_recons_norms)\n",
    "    np.save(base_folder+ 'Ylr_recons_norms', dif_norm_hrs)\n",
    "    np.save(base_folder+ 'Yhr_norms', dif_norm_lrs)\n",
    "    np.save(base_folder+ 'Ylr_norms', Yhr_recons_norms)\n",
    "    \n",
    "    np.save(base_folder+ 'max_vals_hr_r', max_vals_hr_r)\n",
    "    np.save(base_folder+ 'min_vals_hr_r', min_vals_hr_r)\n",
    "    np.save(base_folder+ 'max_vals_lr_r', max_vals_hr_r)\n",
    "    np.save(base_folder+ 'min_vals_lr_r', min_vals_hr_r)\n",
    "    \n",
    "    np.save(base_folder+ 'times' , times)\n",
    "    np.save(base_folder+ 'optimal_vals', optimal_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_utils._isc(A, i_hr, b=1, vmax=np.std(i_hr)+i_hr.mean(), vmin=0, titles=['^Yhr', 'Yhr'])\n",
    "\n",
    "#img_utils._is(A, vmin=A.min(), vmax=A.max())\n",
    "print 'recons', (A.min(), A.mean(), A.max())\n",
    "print 'orig',(i_hr.min(), i_hr.mean(), i_hr.max())\n",
    "#G.shape\n",
    "\n",
    "print 'con la primer forma de tvnorm'\n",
    "print 'dif_norm_hrs', dif_norm_hrs\n",
    "print 'dif_norm_lrs', dif_norm_lrs   \n",
    "print 'Yhr_recons_norms', Yhr_recons_norms\n",
    "print 'Ylr_recons_norms', Ylr_recons_norms\n",
    "print 'Yhr_norms', Yhr_norms\n",
    "print 'Ylr_norms', Ylr_norms\n",
    "print 'times',times\n",
    "print 'optimal_vals', optimal_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HR Testing reconstruction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mse = ((A-i_hr)**2).mean(axis=3)\n",
    "print 'mse=', ((A-i_hr)**2).mean()\n",
    "\n",
    "bval = 5\n",
    "titles = ['^Yhr '+str(int(gtab.bvals[bval])), 'Yhr', 'mse']\n",
    "plt, _, _, im3 = img_utils._isc3(A, i_hr, mse,  b=bval,  vmin=[0, 61104], vmax=[12425, 324973], titles=titles)\n",
    "plt.colorbar(im3,fraction=0.056, pad=0.04)\n",
    "mm(A[:,6,:, bval]), mm(i_hr[:,6,:, bval]), mm(mse), mse.mean()+ np.std(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errel = errrel_layers(A, i_hr)\n",
    "errs =[errel[:,:,:,b].mean() for b in xrange(A.shape[3])]\n",
    "\n",
    "plt.bar(xrange(A.shape[3]), errs),errs[16], errs[32], gtab.bvals[16], gtab.bvals[32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR Testing reconstruction\n",
    "\n",
    "$ G*Yhr = Yhr^* $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def errrel_layers(A, B):\n",
    "    err_rel = np.zeros(A.shape)\n",
    "    for b in xrange(A.shape[3]):\n",
    "        err_rel[:,:,:,b] = np.divide(np.abs(A[:,:,:,b]-B[:,:,:,b]), B[:,:,:,b]+0.01)\n",
    "    return err_rel\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mse_lr = errrel_layers(B,i_lr)\n",
    "#mse_lr = ((mat_utils.normalize(B)-mat_utils.normalize(i_lr))**2).mean(axis=3)\n",
    "#mse_lr = ((np.divide(B-i_lr, i_lr))**2).mean(axis=3)\n",
    "print mse_lr.shape, 'mse:',mm(mse_lr), mse_lr.mean(), np.std(mse_lr), 'B:',mm(B),'i_lr:', mm(i_lr)\n",
    "\n",
    "reload(img_utils)\n",
    "plt, _, _, im3 = img_utils._isc3(B, i_lr, mse_lr,  b=4, vmin=[73, 0], vmax=[12000,2],)\n",
    "plt.colorbar(im3,fraction=0.056, pad=0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Mapl reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Nx, Ny, Nz, Nb = i_hr.shape\n",
    "Nb, Nc =  M.shape\n",
    "Eq_reconst = mapl_predict(gtab, C.reshape((Nx*Ny*Nz, Nc), order='F'), M, tau, Nx, Ny, Nz)\n",
    "\n",
    "\n",
    "err = np.abs(Eq_reconst - i_hr)\n",
    "err_rel = np.divide(err, i_hr+1)#para q no de infinito\n",
    "\n",
    "print mm(err) \n",
    "print 'Error relativo max,min u std', mm(err_rel), int(err_rel.mean()), \\\n",
    "                                      int(np.std(err_rel)) \n",
    "\n",
    "#img_utils._isc(i_hr, Eq_reconst,b=b, vmin=0, vmax=i_hr.max(), titles=['i_hr', 'cvxpy'])\n",
    "img_utils._isc(i_hr, Eq_reconst,b=4, vmin=111, vmax=16402, titles=['i_hr', 'cvxpy'])\n",
    "print 'max/min i_hr:',mm(i_hr),'Eq:', mm(Eq_reconst), Eq_reconst.mean()\n",
    "\n",
    "\"\"\"\n",
    "MAPL SALE PAL TRASTE PORQ \n",
    "precisa mas de 6 puntos \n",
    "- probar con menos orden \n",
    "- probar con minimo 40 puntos y q dios ayude a la compu!!!\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
