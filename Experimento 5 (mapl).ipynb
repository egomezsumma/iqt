{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizacion con MAPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'utils.img_utils' from 'utils/img_utils.pyc'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import img_utils\n",
    "import seaborn as sns\n",
    "import utils.math_utils as mu\n",
    "import nibabel as nib\n",
    "from mapmri import mapmri\n",
    "from dipy.core.gradients import gradient_table\n",
    "import cvxpy as cvx\n",
    "reload(img_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_subject(index, numbers, bval=None, bvalpos=None ):\n",
    "    subject = str(numbers[index])\n",
    "    folder = './HCP/'+subject+'/'\n",
    "    bvals = np.loadtxt(folder+ 'bvals_'+subject)\n",
    "    bvecs = np.loadtxt(folder+'bvecs_'+subject)\n",
    "    \n",
    "    if bvalpos is not None:\n",
    "        img = nib.load(folder+ 'data_small_12x12x12x6_'+subject+'_b'+str(bval)+'.nii.gz')\n",
    "        gtab = gradient_table(bvals=bvals[bvalpos], bvecs=bvecs[:,bvalpos])\n",
    "    else:\n",
    "        img = nib.load(folder+ 'data_small_12x12x12x6_'+subject+'.nii.gz')\n",
    "        gtab = gradient_table(bvals=bvals, bvecs=bvecs)\n",
    "    return img, gtab\n",
    "\n",
    "def get_sample(index, numbers, bval=None, bvalpos=None,  scale=2):\n",
    "    img, gtab = load_subject(index, numbers, bval, bvalpos)\n",
    "    lr, lr_affine = img_utils.downsampling(img, scale)\n",
    "    return img.get_data(), lr\n",
    "\n",
    "def get_sample_maker(numbers, bval=None, bvalpos=None, scale=2):\n",
    "    return lambda index : get_sample(index, numbers, bval, bvalpos,  scale)\n",
    "\n",
    "def mm(A):\n",
    "    return (A.min(), A.max())\n",
    "    \n",
    "def buildT(sample_getter, n_samples):\n",
    "    noised_hr, noised_lr = sample_getter(0)\n",
    "    X = img_utils.column_this(noised_lr)\n",
    "    Y = img_utils.column_this(noised_hr)\n",
    "    for i in range(1, n_samples):\n",
    "        noised_hr, noised_lr = sample_getter(i)\n",
    "        X = img_utils.append_column(X, noised_lr)\n",
    "        Y = img_utils.append_column(Y, noised_hr)\n",
    "    return X, Y\n",
    "\n",
    "## Example of use\n",
    "#buildT(get_sample_maker(numbers, scale), n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem definition\n",
    "\n",
    "expectativa:\n",
    "\n",
    "$ \\min_{Y^{hr},C} \\{ ||GY^{lr} - Y^{hr}||^2 + || Y^{lr} - S_0*\\phi*C||^2 \\}$\n",
    "\n",
    "\n",
    "realidad:\n",
    "\n",
    "\n",
    "$ \\min_{Y^{hr},C} \\{ ||GY^{lr} - Y^{hr}||^2 + \\sum_{i}^{vhr} || (Y^{lr}_{i}, Y^{lr}_{i+1vhr}, Y^{lr}_{i+2vhr}, Y^{lr}_{i+3vhr}, Y^{lr}_{i+4vhr},Y^{lr}_{i+5vhr}) - S_0*\\phi*C_{i}||^2 \\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNOTAS:\\n - la primera formulacion funciono bastante bien (con la sum de los sum_squears) fue \\n   sacado el metodo para preservarlo\\n - probe con la lista de constraints de mapl con igualdad dio todos infeasibles\\n   (proximo a probar lo mismo con desigualdad a un epsilon en vez de igualdad)\\n - \\n   \\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def mapl_parameters(gtab):\n",
    "    radial_order = 6\n",
    "    map_model = mapmri.MapmriModel(gtab,\n",
    "                                radial_order=radial_order,\n",
    "                                anisotropic_scaling=False,\n",
    "                                dti_scale_estimation=False)\n",
    "\n",
    "\n",
    "    mu = map_model.mu\n",
    "    tau = 1 / (4 * np.pi ** 2) # hasta encontrar el big y small delta en HCP\n",
    "    qvals = np.sqrt(gtab.bvals / tau) / (2 * np.pi)\n",
    "    q = gtab.bvecs * qvals[:, None]\n",
    "    M = mapmri.mapmri_isotropic_phi_matrix(radial_order, mu[0], q)\n",
    "    return M\n",
    "\n",
    "\n",
    "def define_problem_with_mapl_primeraQAnduvoBien(i_lr, i_hr_shape, downsampling_matrix, gtab, scale):\n",
    "    Nx, Ny, Nz, bval = i_hr_shape\n",
    "    vhrb = Nx*Ny*Nz*bval\n",
    "    vlr = Nx*Ny*Nz/(scale**3)\n",
    "    vhr = Nx*Ny*Nz\n",
    "      \n",
    "    Yhr = cvx.Variable(vhrb, 1)\n",
    "    #Yhr.value = np.ones((vhrb, 1))*i_lr.mean()\n",
    "    \n",
    "    Ylr = cvx.Parameter(vlr*bval, 1, sign=\"positive\")\n",
    "    Ylr.value = i_lr.reshape((vlr*bval, 1), order='F')\n",
    "    \n",
    "    G = cvx.Parameter(vlr*bval, vhrb)\n",
    "    G.value = downsampling_matrix\n",
    "\n",
    "    # MAPL params\n",
    "    S0 = cvx.Parameter()\n",
    "    S0.value = 100    \n",
    "    M = cvx.Parameter(bval, 50)\n",
    "    M.value = mapl_parameters(gtab)\n",
    "    C = cvx.Variable(Nx*Ny*Nz, 50)\n",
    "    \n",
    "    mapl = sum([cvx.sum_squares( M*C[i,:].T - Yhr[i:vhrb:vhr]) for i in xrange(vhr)])\n",
    "    \n",
    "    # Form objective.\n",
    "    obj = cvx.Minimize(cvx.sum_squares(G*Yhr - Ylr) + mapl)\n",
    "\n",
    "    # Create two constraints.\n",
    "    #constraints = [Yhr >= 0]\n",
    "\n",
    "    # Form and solve problem.\n",
    "    prob = cvx.Problem(obj)\n",
    "    return prob, Yhr, Ylr, G\n",
    "\n",
    "\n",
    "def define_problem_with_mapl(i_lr, i_hr_shape, downsampling_matrix, gtab, scale):\n",
    "    Nx, Ny, Nz, bval = i_hr_shape\n",
    "    vhrb = Nx*Ny*Nz*bval\n",
    "    vlr = Nx*Ny*Nz/(scale**3)\n",
    "    vhr = Nx*Ny*Nz\n",
    "      \n",
    "    Yhr = cvx.Variable(vhrb, 1)\n",
    "    #Yhr.value = np.ones((vhrb, 1))*i_lr.mean()\n",
    "    \n",
    "    Ylr = cvx.Parameter(vlr*bval, 1, sign=\"positive\")\n",
    "    Ylr.value = i_lr.reshape((vlr*bval, 1), order='F')\n",
    "    \n",
    "    G = cvx.Parameter(vlr*bval, vhrb)\n",
    "    G.value = downsampling_matrix\n",
    "\n",
    "    # MAPL params\n",
    "    S0 = cvx.Parameter()\n",
    "    S0.value = 100    \n",
    "    M = cvx.Parameter(bval, 50)\n",
    "    M.value = mapl_parameters(gtab)\n",
    "    C = cvx.Variable(Nx*Ny*Nz, 50)\n",
    "    \n",
    "    #mapl = sum([cvx.sum_squares(M*C[i,:].T - Yhr[i:vhrb:vhr]) for i in xrange(vhr)])\n",
    "    #Yhr_mapl = cvx.vstack([M*C[i,:].T for i in xrange(vhr)])\n",
    "    epsilon = cvx.Parameter()\n",
    "    epsilon.value = (np.linalg.norm(i_lr)**2)*0.9\n",
    "    print \"EPSILON = \", epsilon.value\n",
    "    mapl_eq = [cvx.sum_squares(M*C[i,:].T-Yhr[i:vhrb:vhr]) <= epsilon for i in xrange(vhr)]\n",
    "    \n",
    "    # Form objective.\n",
    "    obj = cvx.Minimize(cvx.sum_squares(G*Yhr - Ylr))\n",
    "\n",
    "    # Create two constraints.\n",
    "    #constraints = [Yhr >= 0, mapl <= epsilon*vhr*bval]\n",
    "\n",
    "    # Form and solve problem.\n",
    "    prob = cvx.Problem(obj, mapl_eq)\n",
    "    return prob, Yhr, Ylr, G\n",
    "\n",
    "\"\"\"\n",
    "NOTAS:\n",
    " - la primera formulacion funciono bastante bien (con la sum de los sum_squears) fue \n",
    "   sacado el metodo para preservarlo\n",
    " - probe con la lista de constraints de mapl con igualdad dio todos infeasibles\n",
    "   (proximo a probar lo mismo con desigualdad a un epsilon en vez de igualdad)\n",
    " - \n",
    "   \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def solveMin(i_lr, i_hr_shape, downsampling_matrix, gtab, scale=2, max_iters=1500, verbose=False):\n",
    "    #prob, Yhr, Ylr, G = define_problem(i_lr, i_hr_shape, downsampling_matrix, scale)\n",
    "    #prob, Yhr, Ylr, G = define_problem_with_tv(i_lr, i_hr_shape, downsampling_matrix, scale)\n",
    "    prob, Yhr, Ylr, G = define_problem_with_mapl(i_lr, i_hr_shape, downsampling_matrix, gtab, scale)\n",
    "       \n",
    "    start_time = time.time()\n",
    "    res = prob.solve(solver='SCS', max_iters=max_iters, eps=1.00e-01, verbose=verbose )  # Returns the optimal value.\n",
    "    #res = prob.solve(solver='ECOS', verbose=verbose )  # Returns the optimal value.\n",
    "    \"\"\"\n",
    "        'max_iters'\n",
    "            maximum number of iterations (default: 100).\n",
    "        'abstol'\n",
    "            absolute accuracy (default: 1e-7).\n",
    "        'reltol'\n",
    "            relative accuracy (default: 1e-6).\n",
    "        'feastol'\n",
    "            tolerance for feasibility conditions (default: 1e-7).\n",
    "        'abstol_inacc'\n",
    "            absolute accuracy for inaccurate solution (default: 5e-5).\n",
    "        'reltol_inacc'\n",
    "            relative accuracy for inaccurate solution (default: 5e-5).\n",
    "        'feastol_inacc'\n",
    "            tolerance for feasibility condition for inaccurate solution (default: 1e-4). \n",
    "    \"\"\"\n",
    "    \n",
    "    seg = time.time() - start_time\n",
    "\n",
    "    minutes = int(seg / 60)\n",
    "    print(\"--- time of optimization : %d' %d'' ---\" % (minutes , seg%60))\n",
    "    print \"--- status:\", prob.status, \"optimal value\", prob.value\n",
    "    print \n",
    "\n",
    "    # Change dimension of result representation\n",
    "    if Yhr.value is None :\n",
    "        #Yhr.value = np.ones(i_hr_shape)\n",
    "        print 'FRECONSTRUCTION FAIL :('\n",
    "        A = np.zeros(i_hr_shape,dtype='float32')\n",
    "    else:    \n",
    "        A = np.asarray(Yhr.value, dtype='float32').reshape(i_hr_shape, order='F')\n",
    "        \n",
    "    return A, seg, prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the problem and cross-validation (leave one out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Leaving out: # 180937\n",
      "SAMPLES min/max  29.1264362335 2830.05957031 12.4889230728 3112.2512207\n",
      "= Training and fiting ...\n",
      "= Solving optimization problem ...\n",
      "WARN: m less than n, problem likely degenerate\n",
      "----------------------------------------------------------------------------\n",
      "\tSCS v1.2.6 - Splitting Conic Solver\n",
      "\t(c) Brendan O'Donoghue, Stanford University, 2012-2016\n",
      "----------------------------------------------------------------------------\n",
      "Lin-sys: sparse-indirect, nnz in A = 13970882, CG tol ~ 1/iter^(2.00)\n",
      "eps = 1.00e-01, alpha = 1.50, max_iters = 1500, normalize = 1, scale = 1.00\n",
      "Variables n = 98497, constraints m = 16850\n",
      "Cones:\tlinear vars: 1728\n",
      "\tsoc vars: 15122, soc blks: 1729\n",
      "Setup time: 7.28e-01s\n",
      "----------------------------------------------------------------------------\n",
      " Iter | pri res | dua res | rel gap | pri obj | dua obj | kap/tau | time (s)\n",
      "----------------------------------------------------------------------------\n",
      "     0|      inf       inf      -nan      -inf       inf       inf  1.77e+00 \n",
      "   100| 3.04e-01  1.07e-02  1.04e-03  3.13e+05  3.12e+05  1.52e-12  3.94e+01 \n",
      "   200| 3.03e-01  1.09e-02  6.83e-04  6.28e+05  6.28e+05  1.53e-12  9.26e+01 \n",
      "   220| 3.03e-01  1.09e-02  6.34e-04  6.92e+05  6.91e+05  1.86e-12  1.04e+02 \n",
      "----------------------------------------------------------------------------\n",
      "Status: Infeasible\n",
      "Timing: Solve time: 1.04e+02s\n",
      "\tLin-sys: avg # CG iterations: 10.64, avg solve time: 4.70e-01s\n",
      "\tCones: avg projection time: 2.22e-05s\n",
      "----------------------------------------------------------------------------\n",
      "Certificate of primal infeasibility:\n",
      "dist(y, K*) = 2.1684e-19\n",
      "|A'y|_2 * |b|_2 = 9.2751e-02\n",
      "b'y = -1.0000\n",
      "============================================================================\n",
      "--- time of optimization : 2' 14'' ---\n",
      "--- status: infeasible optimal value inf\n",
      "\n",
      "FRECONSTRUCTION FAIL :(\n",
      "= Calculating metrics...\n",
      "showing hr 180937 min, max (0.0, 0.0)\n",
      "saved A in:  ./resultados/exp5/A/hrRec_lo180937.npy\n",
      "showing lr 180937 min, max (136.08327762918259, 1777.7107171056055)\n",
      "saved A in:  ./resultados/exp5/lrRec_lo180937.npy\n",
      "\n",
      "\n",
      "== Leaving out: # 100307\n",
      "SAMPLES min/max  29.1264362335 2830.05957031 12.4889230728 3112.2512207\n",
      "= Training and fiting ...\n",
      "= Solving optimization problem ...\n",
      "WARN: m less than n, problem likely degenerate\n",
      "----------------------------------------------------------------------------\n",
      "\tSCS v1.2.6 - Splitting Conic Solver\n",
      "\t(c) Brendan O'Donoghue, Stanford University, 2012-2016\n",
      "----------------------------------------------------------------------------\n",
      "Lin-sys: sparse-indirect, nnz in A = 13970882, CG tol ~ 1/iter^(2.00)\n",
      "eps = 1.00e-01, alpha = 1.50, max_iters = 1500, normalize = 1, scale = 1.00\n",
      "Variables n = 98497, constraints m = 16850\n",
      "Cones:\tlinear vars: 1728\n",
      "\tsoc vars: 15122, soc blks: 1729\n",
      "Setup time: 7.20e-01s\n",
      "----------------------------------------------------------------------------\n",
      " Iter | pri res | dua res | rel gap | pri obj | dua obj | kap/tau | time (s)\n",
      "----------------------------------------------------------------------------\n",
      "     0|      inf       inf      -nan      -inf       inf       inf  1.84e+00 \n",
      "   100| 4.04e-01  1.97e-02  1.29e-03  6.38e+05  6.37e+05  3.08e-12  4.04e+01 \n",
      "   120| 4.03e-01  1.98e-02  1.13e-03  7.67e+05  7.65e+05  2.22e-12  5.14e+01 \n",
      "----------------------------------------------------------------------------\n",
      "Status: Infeasible\n",
      "Timing: Solve time: 5.14e+01s\n",
      "\tLin-sys: avg # CG iterations: 9.12, avg solve time: 4.21e-01s\n",
      "\tCones: avg projection time: 2.25e-05s\n",
      "----------------------------------------------------------------------------\n",
      "Certificate of primal infeasibility:\n",
      "dist(y, K*) = 5.4210e-20\n",
      "|A'y|_2 * |b|_2 = 9.1845e-02\n",
      "b'y = -1.0000\n",
      "============================================================================\n",
      "--- time of optimization : 1' 21'' ---\n",
      "--- status: infeasible optimal value inf\n",
      "\n",
      "FRECONSTRUCTION FAIL :(\n",
      "= Calculating metrics...\n",
      "showing hr 100307 min, max (0.0, 0.0)\n",
      "saved A in:  ./resultados/exp5/A/hrRec_lo100307.npy\n",
      "showing lr 100307 min, max (184.04265327716803, 1772.8766956070024)\n",
      "saved A in:  ./resultados/exp5/lrRec_lo100307.npy\n",
      "\n",
      "\n",
      "== Leaving out: # 100408\n",
      "SAMPLES min/max  29.1264362335 2830.05957031 12.4889230728 3112.2512207\n",
      "= Training and fiting ...\n",
      "= Solving optimization problem ...\n",
      "WARN: m less than n, problem likely degenerate\n",
      "----------------------------------------------------------------------------\n",
      "\tSCS v1.2.6 - Splitting Conic Solver\n",
      "\t(c) Brendan O'Donoghue, Stanford University, 2012-2016\n",
      "----------------------------------------------------------------------------\n",
      "Lin-sys: sparse-indirect, nnz in A = 13970882, CG tol ~ 1/iter^(2.00)\n",
      "eps = 1.00e-01, alpha = 1.50, max_iters = 1500, normalize = 1, scale = 1.00\n",
      "Variables n = 98497, constraints m = 16850\n",
      "Cones:\tlinear vars: 1728\n",
      "\tsoc vars: 15122, soc blks: 1729\n",
      "Setup time: 6.48e-01s\n",
      "----------------------------------------------------------------------------\n",
      " Iter | pri res | dua res | rel gap | pri obj | dua obj | kap/tau | time (s)\n",
      "----------------------------------------------------------------------------\n",
      "     0|      inf       inf      -nan      -inf       inf       inf  1.76e+00 \n",
      "   100| 3.42e-01  1.37e-02  1.16e-03  4.97e+05  4.96e+05  2.41e-12  4.04e+01 \n",
      "   160| 3.41e-01  1.39e-02  8.50e-04  7.98e+05  7.96e+05  3.10e-12  7.64e+01 \n",
      "----------------------------------------------------------------------------\n",
      "Status: Infeasible\n",
      "Timing: Solve time: 7.64e+01s\n",
      "\tLin-sys: avg # CG iterations: 10.50, avg solve time: 4.71e-01s\n",
      "\tCones: avg projection time: 2.21e-05s\n",
      "----------------------------------------------------------------------------\n",
      "Certificate of primal infeasibility:\n",
      "dist(y, K*) = 0.0000e+00\n",
      "|A'y|_2 * |b|_2 = 9.9355e-02\n",
      "b'y = -1.0000\n",
      "============================================================================\n",
      "--- time of optimization : 1' 45'' ---\n",
      "--- status: infeasible optimal value inf\n",
      "\n",
      "FRECONSTRUCTION FAIL :(\n",
      "= Calculating metrics...\n",
      "showing hr 100408 min, max (0.0, 0.0)\n",
      "saved A in:  ./resultados/exp5/A/hrRec_lo100408.npy\n",
      "showing lr 100408 min, max (161.8147595490509, 2240.9995335321964)\n",
      "saved A in:  ./resultados/exp5/lrRec_lo100408.npy\n",
      "\n",
      "\n",
      "== Leaving out: # 180129\n",
      "SAMPLES min/max  29.1264362335 2830.05957031 12.4889230728 3112.2512207\n",
      "= Training and fiting ...\n",
      "= Solving optimization problem ...\n",
      "WARN: m less than n, problem likely degenerate\n",
      "----------------------------------------------------------------------------\n",
      "\tSCS v1.2.6 - Splitting Conic Solver\n",
      "\t(c) Brendan O'Donoghue, Stanford University, 2012-2016\n",
      "----------------------------------------------------------------------------\n",
      "Lin-sys: sparse-indirect, nnz in A = 13970882, CG tol ~ 1/iter^(2.00)\n",
      "eps = 1.00e-01, alpha = 1.50, max_iters = 1500, normalize = 1, scale = 1.00\n",
      "Variables n = 98497, constraints m = 16850\n",
      "Cones:\tlinear vars: 1728\n",
      "\tsoc vars: 15122, soc blks: 1729\n",
      "Setup time: 6.51e-01s\n",
      "----------------------------------------------------------------------------\n",
      " Iter | pri res | dua res | rel gap | pri obj | dua obj | kap/tau | time (s)\n",
      "----------------------------------------------------------------------------\n",
      "     0|      inf       inf      -nan      -inf       inf       inf  1.80e+00 \n",
      "   100| 2.78e-01  8.86e-03  9.29e-04  2.64e+05  2.63e+05  2.56e-12  4.01e+01 \n",
      "   200| 2.77e-01  9.06e-03  6.56e-04  5.31e+05  5.30e+05  2.59e-12  9.99e+01 \n",
      "   260| 2.77e-01  9.08e-03  5.37e-04  6.91e+05  6.90e+05  2.20e-12  1.39e+02 \n",
      "----------------------------------------------------------------------------\n",
      "Status: Infeasible\n",
      "Timing: Solve time: 1.39e+02s\n",
      "\tLin-sys: avg # CG iterations: 11.99, avg solve time: 5.29e-01s\n",
      "\tCones: avg projection time: 2.23e-05s\n",
      "----------------------------------------------------------------------------\n",
      "Certificate of primal infeasibility:\n",
      "dist(y, K*) = 2.1684e-19\n",
      "|A'y|_2 * |b|_2 = 9.4720e-02\n",
      "b'y = -1.0000\n",
      "============================================================================\n",
      "--- time of optimization : 2' 48'' ---\n",
      "--- status: infeasible optimal value inf\n",
      "\n",
      "FRECONSTRUCTION FAIL :(\n",
      "= Calculating metrics...\n",
      "showing hr 180129 min, max (0.0, 0.0)\n",
      "saved A in:  ./resultados/exp5/A/hrRec_lo180129.npy\n",
      "showing lr 180129 min, max (165.20943635804639, 1914.2348382528487)\n",
      "saved A in:  ./resultados/exp5/lrRec_lo180129.npy\n",
      "\n",
      "\n",
      "== Leaving out: # 180432\n",
      "SAMPLES min/max  29.1264362335 2830.05957031 12.4889230728 3112.2512207\n",
      "= Training and fiting ...\n",
      "= Solving optimization problem ...\n",
      "WARN: m less than n, problem likely degenerate\n",
      "----------------------------------------------------------------------------\n",
      "\tSCS v1.2.6 - Splitting Conic Solver\n",
      "\t(c) Brendan O'Donoghue, Stanford University, 2012-2016\n",
      "----------------------------------------------------------------------------\n",
      "Lin-sys: sparse-indirect, nnz in A = 13970882, CG tol ~ 1/iter^(2.00)\n",
      "eps = 1.00e-01, alpha = 1.50, max_iters = 1500, normalize = 1, scale = 1.00\n",
      "Variables n = 98497, constraints m = 16850\n",
      "Cones:\tlinear vars: 1728\n",
      "\tsoc vars: 15122, soc blks: 1729\n",
      "Setup time: 7.15e-01s\n",
      "----------------------------------------------------------------------------\n",
      " Iter | pri res | dua res | rel gap | pri obj | dua obj | kap/tau | time (s)\n",
      "----------------------------------------------------------------------------\n",
      "     0|      inf       inf      -nan      -inf       inf       inf  1.82e+00 \n",
      "   100| 3.98e-01  1.91e-02  1.28e-03  4.25e+05  4.24e+05  2.05e-12  4.04e+01 \n",
      "   120| 3.97e-01  1.91e-02  1.12e-03  5.10e+05  5.09e+05  1.48e-12  5.23e+01 \n",
      "----------------------------------------------------------------------------\n",
      "Status: Infeasible\n",
      "Timing: Solve time: 5.23e+01s\n",
      "\tLin-sys: avg # CG iterations: 9.22, avg solve time: 4.29e-01s\n",
      "\tCones: avg projection time: 2.26e-05s\n",
      "----------------------------------------------------------------------------\n",
      "Certificate of primal infeasibility:\n",
      "dist(y, K*) = 2.1684e-19\n",
      "|A'y|_2 * |b|_2 = 9.4938e-02\n",
      "b'y = -1.0000\n",
      "============================================================================\n",
      "--- time of optimization : 1' 22'' ---\n",
      "--- status: infeasible optimal value inf\n",
      "\n",
      "FRECONSTRUCTION FAIL :(\n",
      "= Calculating metrics...\n",
      "showing hr 180432 min, max (0.0, 0.0)\n",
      "saved A in:  ./resultados/exp5/A/hrRec_lo180432.npy\n",
      "showing lr 180432 min, max (37.113452971985467, 1335.2413315802719)\n",
      "saved A in:  ./resultados/exp5/lrRec_lo180432.npy\n",
      "\n",
      "\n",
      "== Leaving out: # 180836\n",
      "SAMPLES min/max  29.1264362335 2830.05957031 12.4889230728 3112.2512207\n",
      "= Training and fiting ...\n",
      "= Solving optimization problem ...\n",
      "WARN: m less than n, problem likely degenerate\n",
      "----------------------------------------------------------------------------\n",
      "\tSCS v1.2.6 - Splitting Conic Solver\n",
      "\t(c) Brendan O'Donoghue, Stanford University, 2012-2016\n",
      "----------------------------------------------------------------------------\n",
      "Lin-sys: sparse-indirect, nnz in A = 13970882, CG tol ~ 1/iter^(2.00)\n",
      "eps = 1.00e-01, alpha = 1.50, max_iters = 1500, normalize = 1, scale = 1.00\n",
      "Variables n = 98497, constraints m = 16850\n",
      "Cones:\tlinear vars: 1728\n",
      "\tsoc vars: 15122, soc blks: 1729\n",
      "Setup time: 6.53e-01s\n",
      "----------------------------------------------------------------------------\n",
      " Iter | pri res | dua res | rel gap | pri obj | dua obj | kap/tau | time (s)\n",
      "----------------------------------------------------------------------------\n",
      "     0|      inf       inf      -nan      -inf       inf       inf  1.79e+00 \n",
      "   100| 3.69e-01  1.62e-02  1.23e-03  6.43e+05  6.42e+05  3.11e-12  4.26e+01 \n",
      "   140| 3.68e-01  1.63e-02  9.70e-04  9.02e+05  9.01e+05  3.06e-12  6.68e+01 \n",
      "----------------------------------------------------------------------------\n",
      "Status: Infeasible\n",
      "Timing: Solve time: 6.68e+01s\n",
      "\tLin-sys: avg # CG iterations: 10.16, avg solve time: 4.70e-01s\n",
      "\tCones: avg projection time: 2.27e-05s\n",
      "----------------------------------------------------------------------------\n",
      "Certificate of primal infeasibility:\n",
      "dist(y, K*) = 0.0000e+00\n",
      "|A'y|_2 * |b|_2 = 9.6204e-02\n",
      "b'y = -1.0000\n",
      "============================================================================\n",
      "--- time of optimization : 1' 36'' ---\n",
      "--- status: infeasible optimal value inf\n",
      "\n",
      "FRECONSTRUCTION FAIL :(\n",
      "= Calculating metrics...\n",
      "showing hr 180836 min, max (0.0, 0.0)\n",
      "saved A in:  ./resultados/exp5/A/hrRec_lo180836.npy\n",
      "showing lr 180836 min, max (230.46642406254415, 2291.8839364244395)\n",
      "saved A in:  ./resultados/exp5/lrRec_lo180836.npy\n",
      "\n",
      "\n",
      " === TOTAL TIME : 11' 8\"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAADFCAYAAACW0gNvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb267227d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import experimento1_funciones as e1f\n",
    "reload(img_utils)\n",
    "\n",
    "RES_BASE_FOLDER = './resultados/exp5/'\n",
    "VMIN, VMAX=-50, 2500\n",
    "\n",
    "voi_hr_shape = (12, 12, 12, 6)\n",
    "voi_lr_shape = (6, 6, 6, 6)\n",
    "subjects = [100307, 100408, 180129, 180432, 180836, 180937]\n",
    "bvals2000pos = [18, 27, 69, 75, 101, 107]\n",
    "# Esto es para quedame con la gtab que es igua a todos\n",
    "img, gtab = load_subject(0,subjects, bval=2000, bvalpos=bvals2000pos)\n",
    "del img\n",
    "sample_maker = get_sample_maker(subjects, bval=2000, bvalpos=bvals2000pos, scale=2)\n",
    "\n",
    "n_samples = 6\n",
    "iterations = 6\n",
    "\n",
    "# Metrics to save\n",
    "min_vals_hr_r = []\n",
    "max_vals_hr_r = []\n",
    "min_vals_lr_r = []\n",
    "max_vals_lr_r = []\n",
    "\n",
    "dif_norm_hrs=[]\n",
    "dif_norm_lrs=[]    \n",
    "Yhr_recons_norms=[]\n",
    "Ylr_recons_norms=[]  \n",
    "Yhr_norms=[]\n",
    "Ylr_norms=[]\n",
    "times = []\n",
    "optimal_vals = []\n",
    "\n",
    "base_folder = RES_BASE_FOLDER\n",
    "#base_folder = None\n",
    "\n",
    "for i in range(0, iterations):\n",
    "    subject = str(subjects[len(subjects)-1])\n",
    "    print '== Leaving out: #', subject\n",
    "    \n",
    "    ### Aca shiftear el arreglo de sujetos (train deja el ultimo afuera del entrenamiento)\n",
    "    subjects.append(subjects.pop(0))\n",
    "    lr_samples, hr_samples = buildT(sample_maker, n_samples) #lr, hr\n",
    "\n",
    "    #lr_samples, hr_samples = lr_samples/1589, hr_samples/1589\n",
    "    print 'SAMPLES min/max ', lr_samples.min(),lr_samples.max(),  hr_samples.min(), hr_samples.max()\n",
    "    \n",
    "    # Build downsampling matrix\n",
    "    print '= Training and fiting ...'\n",
    "    regr, hr_train , lr_train, hr_test, lr_test = e1f.train(hr_samples, lr_samples)\n",
    "    regr.coef_ = csr_matrix(regr.coef_)\n",
    "    \n",
    "    # Reshape the one that left out to validate\n",
    "    i_lr = lr_test.reshape(voi_lr_shape, order='F')\n",
    "    i_hr = hr_test.reshape(voi_hr_shape, order='F')\n",
    "    \n",
    "    # Minimization solve\n",
    "    # mock: A, seg = np.ones(i_hr.shape), 20\n",
    "    print '= Solving optimization problem ...'\n",
    "    A, seg, prob = solveMin(i_lr, i_hr.shape, regr.coef_, gtab, scale=2, max_iters=1500, verbose=True)\n",
    "    max_vals_hr_r.append(A.max())\n",
    "    min_vals_hr_r.append(A.min())\n",
    "    \n",
    "    B = (regr.coef_*i_hr.reshape(-1, order='F')).reshape(voi_lr_shape, order='F')\n",
    "    max_vals_lr_r.append(B.max())\n",
    "    min_vals_lr_r.append(B.min())\n",
    "    \n",
    "    # Keep parameters\n",
    "    print '= Calculating metrics...'\n",
    "    dif_norm_hr = np.linalg.norm(i_hr-A) # recons-gtrust\n",
    "    Yhr_norm = np.linalg.norm(i_hr)\n",
    "    Yhr_recons_norm = np.linalg.norm(A) #recons\n",
    "    \n",
    "    dif_norm_lr = np.linalg.norm(i_lr-B)\n",
    "    Ylr_norm = np.linalg.norm(B)\n",
    "    Ylr_recons_norm = np.linalg.norm(B)\n",
    "    \n",
    "    dif_norm_hrs.append(dif_norm_hr)\n",
    "    dif_norm_lrs.append(dif_norm_lr)\n",
    "    \n",
    "    Yhr_recons_norms.append(Yhr_recons_norm)\n",
    "    Ylr_recons_norms.append(Ylr_recons_norm)\n",
    "    \n",
    "    Yhr_norms.append(Yhr_norm)\n",
    "    Ylr_norms.append(Ylr_norm)\n",
    "    \n",
    "    times.append(seg)\n",
    "    optimal_vals.append(prob.value)\n",
    "\n",
    "    # Save the A calculated\n",
    "    if base_folder is not None:\n",
    "        name = base_folder+ \"A/\" + 'hrRec_lo' + subject\n",
    "        np.save(name, A)\n",
    "        print 'showing hr '+ subject, 'min, max',(A.min(), A.max()) \n",
    "        titles=['Reconstruida', 'Original']\n",
    "        for b in xrange(6):\n",
    "            plt = img_utils._isc(A, i_hr,b=b ,titles=titles,  vmax=VMAX, vmin=VMIN)\n",
    "            plt.savefig(name +'b'+str(b)+'.pdf')\n",
    "        print 'saved A in: ', name + str('.npy')\n",
    "        \n",
    "    # Save the B calculated\n",
    "    if base_folder is not None:\n",
    "        name = base_folder + 'lrRec_lo' + subject\n",
    "        np.save(name, B)\n",
    "        print 'showing lr '+ subject, 'min, max',(B.min(), B.max()) \n",
    "        titles=['Reconstruida', 'Original']\n",
    "        plt = img_utils._isc(B, i_lr, titles=titles,  vmax=VMAX, vmin=VMIN)\n",
    "        plt.savefig(name + '.pdf')\n",
    "        print 'saved A in: ', name + str('.npy')\n",
    "        \n",
    "    print\n",
    "    print\n",
    "\n",
    "# Log spended\n",
    "total_sec = np.array(times).sum()\n",
    "print ' === TOTAL TIME :',  str(int(total_sec//60))+\"'\", str(int(total_sec%60))+ '\"'\n",
    "\n",
    "# Persist results\n",
    "if base_folder is not None: \n",
    "    np.save(base_folder+ 'dif_norm_hrs', dif_norm_hrs)\n",
    "    np.save(base_folder+ 'dif_norm_lrs', dif_norm_lrs)\n",
    "    np.save(base_folder+ 'Yhr_recons_norms', Yhr_recons_norms)\n",
    "    np.save(base_folder+ 'Ylr_recons_norms', dif_norm_hrs)\n",
    "    np.save(base_folder+ 'Yhr_norms', dif_norm_lrs)\n",
    "    np.save(base_folder+ 'Ylr_norms', Yhr_recons_norms)\n",
    "    \n",
    "    np.save(base_folder+ 'max_vals_hr_r', max_vals_hr_r)\n",
    "    np.save(base_folder+ 'min_vals_hr_r', min_vals_hr_r)\n",
    "    np.save(base_folder+ 'max_vals_lr_r', max_vals_hr_r)\n",
    "    np.save(base_folder+ 'min_vals_lr_r', min_vals_hr_r)\n",
    "    \n",
    "    np.save(base_folder+ 'times' , times)\n",
    "    np.save(base_folder+ 'optimal_vals', optimal_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
